shadow$provide.module$node_modules$monaco_editor$esm$vs$editor$standalone$common$monarch$monarchLexer = function(require, module, exports) {
  function findBracket(lexer, matched) {
    if (!matched) {
      return null;
    }
    matched = monarchCommon.fixCase(lexer, matched);
    lexer = lexer.brackets;
    for (const bracket of lexer) {
      if (bracket.open === matched) {
        return {token:bracket.token, bracketType:1};
      }
      if (bracket.close === matched) {
        return {token:bracket.token, bracketType:-1};
      }
    }
    return null;
  }
  Object.defineProperties(exports, {__esModule:{enumerable:!0, value:!0}, MonarchTokenizer:{enumerable:!0, get:function() {
    return MonarchTokenizer;
  }}});
  module = require("module$node_modules$monaco_editor$esm$vs$base$common$lifecycle");
  var languages = require("module$node_modules$monaco_editor$esm$vs$editor$common$languages"), require$_DOT__DOT__SLASH__DOT__DOT__SLASH__DOT__DOT__SLASH_common_SLASH_languages_SLASH_nullTokenize_DOT_js = require("module$node_modules$monaco_editor$esm$vs$editor$common$languages$nullTokenize"), monarchCommon = require("module$node_modules$monaco_editor$esm$vs$editor$standalone$common$monarch$monarchCommon");
  require = require("module$node_modules$monaco_editor$esm$vs$platform$configuration$common$configuration");
  exports = this && this.__decorate || function(decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") {
      r = Reflect.decorate(decorators, target, key, desc);
    } else {
      for (var i = decorators.length - 1; i >= 0; i--) {
        if (d = decorators[i]) {
          r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
        }
      }
    }
    return c > 3 && r && Object.defineProperty(target, key, r), r;
  };
  var __param = this && this.__param || function(paramIndex, decorator) {
    return function(target, key) {
      decorator(target, key, paramIndex);
    };
  }, MonarchTokenizer_1;
  class MonarchStackElementFactory {
    static create(parent, state) {
      return this._INSTANCE.create(parent, state);
    }
    constructor(maxCacheDepth) {
      this._maxCacheDepth = maxCacheDepth;
      this._entries = Object.create(null);
    }
    create(parent, state) {
      if (parent !== null && parent.depth >= this._maxCacheDepth) {
        return new MonarchStackElement(parent, state);
      }
      let stackElementId = MonarchStackElement.getStackElementId(parent);
      stackElementId.length > 0 && (stackElementId += "|");
      stackElementId += state;
      let result = this._entries[stackElementId];
      if (result) {
        return result;
      }
      result = new MonarchStackElement(parent, state);
      return this._entries[stackElementId] = result;
    }
  }
  MonarchStackElementFactory._INSTANCE = new MonarchStackElementFactory(5);
  class MonarchStackElement {
    constructor(parent, state) {
      this.parent = parent;
      this.state = state;
      this.depth = (this.parent ? this.parent.depth : 0) + 1;
    }
    static getStackElementId(element) {
      let result = "";
      for (; element !== null;) {
        result.length > 0 && (result += "|"), result += element.state, element = element.parent;
      }
      return result;
    }
    static _equals(a, b) {
      for (; a !== null && b !== null;) {
        if (a === b) {
          return !0;
        }
        if (a.state !== b.state) {
          return !1;
        }
        a = a.parent;
        b = b.parent;
      }
      return a === null && b === null ? !0 : !1;
    }
    equals(other) {
      return MonarchStackElement._equals(this, other);
    }
    push(state) {
      return MonarchStackElementFactory.create(this, state);
    }
    pop() {
      return this.parent;
    }
    popall() {
      let result = this;
      for (; result.parent;) {
        result = result.parent;
      }
      return result;
    }
    switchTo(state) {
      return MonarchStackElementFactory.create(this.parent, state);
    }
  }
  class EmbeddedLanguageData {
    constructor(languageId, state) {
      this.languageId = languageId;
      this.state = state;
    }
    equals(other) {
      return this.languageId === other.languageId && this.state.equals(other.state);
    }
    clone() {
      return this.state.clone() === this.state ? this : new EmbeddedLanguageData(this.languageId, this.state);
    }
  }
  class MonarchLineStateFactory {
    static create(stack, embeddedLanguageData) {
      return this._INSTANCE.create(stack, embeddedLanguageData);
    }
    constructor(maxCacheDepth) {
      this._maxCacheDepth = maxCacheDepth;
      this._entries = Object.create(null);
    }
    create(stack, embeddedLanguageData) {
      if (embeddedLanguageData !== null || stack !== null && stack.depth >= this._maxCacheDepth) {
        return new MonarchLineState(stack, embeddedLanguageData);
      }
      embeddedLanguageData = MonarchStackElement.getStackElementId(stack);
      let result = this._entries[embeddedLanguageData];
      if (result) {
        return result;
      }
      result = new MonarchLineState(stack, null);
      return this._entries[embeddedLanguageData] = result;
    }
  }
  MonarchLineStateFactory._INSTANCE = new MonarchLineStateFactory(5);
  class MonarchLineState {
    constructor(stack, embeddedLanguageData) {
      this.stack = stack;
      this.embeddedLanguageData = embeddedLanguageData;
    }
    clone() {
      return (this.embeddedLanguageData ? this.embeddedLanguageData.clone() : null) === this.embeddedLanguageData ? this : MonarchLineStateFactory.create(this.stack, this.embeddedLanguageData);
    }
    equals(other) {
      return other instanceof MonarchLineState && this.stack.equals(other.stack) ? this.embeddedLanguageData === null && other.embeddedLanguageData === null ? !0 : this.embeddedLanguageData === null || other.embeddedLanguageData === null ? !1 : this.embeddedLanguageData.equals(other.embeddedLanguageData) : !1;
    }
  }
  class MonarchClassicTokensCollector {
    constructor() {
      this._tokens = [];
      this._lastTokenLanguage = this._lastTokenType = this._languageId = null;
    }
    enterLanguage(languageId) {
      this._languageId = languageId;
    }
    emit(startOffset, type) {
      if (this._lastTokenType !== type || this._lastTokenLanguage !== this._languageId) {
        this._lastTokenType = type, this._lastTokenLanguage = this._languageId, this._tokens.push(new languages.Token(startOffset, type, this._languageId));
      }
    }
    nestedLanguageTokenize(embeddedLanguageLine, hasEOL, embeddedLanguageData, offsetDelta) {
      const nestedLanguageId = embeddedLanguageData.languageId;
      embeddedLanguageData = embeddedLanguageData.state;
      const nestedLanguageTokenizationSupport = languages.TokenizationRegistry.get(nestedLanguageId);
      if (!nestedLanguageTokenizationSupport) {
        return this.enterLanguage(nestedLanguageId), this.emit(offsetDelta, ""), embeddedLanguageData;
      }
      embeddedLanguageLine = nestedLanguageTokenizationSupport.tokenize(embeddedLanguageLine, hasEOL, embeddedLanguageData);
      if (offsetDelta !== 0) {
        for (const token of embeddedLanguageLine.tokens) {
          this._tokens.push(new languages.Token(token.offset + offsetDelta, token.type, token.language));
        }
      } else {
        this._tokens = this._tokens.concat(embeddedLanguageLine.tokens);
      }
      this._languageId = this._lastTokenLanguage = this._lastTokenType = null;
      return embeddedLanguageLine.endState;
    }
    finalize(endState) {
      return new languages.TokenizationResult(this._tokens, endState);
    }
  }
  class MonarchModernTokensCollector {
    constructor(languageService, theme) {
      this._languageService = languageService;
      this._theme = theme;
      this._prependTokens = null;
      this._tokens = [];
      this._lastTokenMetadata = this._currentLanguageId = 0;
    }
    enterLanguage(languageId) {
      this._currentLanguageId = this._languageService.languageIdCodec.encodeLanguageId(languageId);
    }
    emit(startOffset, type) {
      type = this._theme.match(this._currentLanguageId, type) | 1024;
      this._lastTokenMetadata !== type && (this._lastTokenMetadata = type, this._tokens.push(startOffset), this._tokens.push(type));
    }
    static _merge(a, b, c) {
      const aLen = a !== null ? a.length : 0, bLen = b.length;
      var cLen = c !== null ? c.length : 0;
      if (aLen === 0 && bLen === 0 && cLen === 0) {
        return new Uint32Array(0);
      }
      if (aLen === 0 && bLen === 0) {
        return c;
      }
      if (bLen === 0 && cLen === 0) {
        return a;
      }
      cLen = new Uint32Array(aLen + bLen + cLen);
      a !== null && cLen.set(a);
      for (a = 0; a < bLen; a++) {
        cLen[aLen + a] = b[a];
      }
      c !== null && cLen.set(c, aLen + bLen);
      return cLen;
    }
    nestedLanguageTokenize(embeddedLanguageLine, hasEOL, embeddedLanguageData, offsetDelta) {
      const nestedLanguageId = embeddedLanguageData.languageId;
      embeddedLanguageData = embeddedLanguageData.state;
      const nestedLanguageTokenizationSupport = languages.TokenizationRegistry.get(nestedLanguageId);
      if (!nestedLanguageTokenizationSupport) {
        return this.enterLanguage(nestedLanguageId), this.emit(offsetDelta, ""), embeddedLanguageData;
      }
      embeddedLanguageLine = nestedLanguageTokenizationSupport.tokenizeEncoded(embeddedLanguageLine, hasEOL, embeddedLanguageData);
      if (offsetDelta !== 0) {
        for (let i = 0, len = embeddedLanguageLine.tokens.length; i < len; i += 2) {
          embeddedLanguageLine.tokens[i] += offsetDelta;
        }
      }
      this._prependTokens = MonarchModernTokensCollector._merge(this._prependTokens, this._tokens, embeddedLanguageLine.tokens);
      this._tokens = [];
      this._lastTokenMetadata = this._currentLanguageId = 0;
      return embeddedLanguageLine.endState;
    }
    finalize(endState) {
      return new languages.EncodedTokenizationResult(MonarchModernTokensCollector._merge(this._prependTokens, this._tokens, null), endState);
    }
  }
  let MonarchTokenizer = MonarchTokenizer_1 = class extends module.Disposable {
    constructor(languageService, standaloneThemeService, languageId, lexer, _configurationService) {
      super();
      this._configurationService = _configurationService;
      this._languageService = languageService;
      this._standaloneThemeService = standaloneThemeService;
      this._languageId = languageId;
      this._lexer = lexer;
      this._embeddedLanguages = Object.create(null);
      this.embeddedLoaded = Promise.resolve(void 0);
      let emitting = !1;
      this._register(languages.TokenizationRegistry.onDidChange(e => {
        if (!emitting) {
          var isOneOfMyEmbeddedModes = !1;
          for (let i = 0, len = e.changedLanguages.length; i < len; i++) {
            if (this._embeddedLanguages[e.changedLanguages[i]]) {
              isOneOfMyEmbeddedModes = !0;
              break;
            }
          }
          isOneOfMyEmbeddedModes && (emitting = !0, languages.TokenizationRegistry.handleChange([this._languageId]), emitting = !1);
        }
      }));
      this._maxTokenizationLineLength = this._configurationService.getValue("editor.maxTokenizationLineLength", {overrideIdentifier:this._languageId});
      this._register(this._configurationService.onDidChangeConfiguration(e => {
        e.affectsConfiguration("editor.maxTokenizationLineLength") && (this._maxTokenizationLineLength = this._configurationService.getValue("editor.maxTokenizationLineLength", {overrideIdentifier:this._languageId}));
      }));
    }
    getLoadStatus() {
      const promises = [];
      for (const nestedLanguageId in this._embeddedLanguages) {
        var tokenizationSupport = languages.TokenizationRegistry.get(nestedLanguageId);
        tokenizationSupport ? tokenizationSupport instanceof MonarchTokenizer_1 && (tokenizationSupport = tokenizationSupport.getLoadStatus(), tokenizationSupport.loaded === !1 && promises.push(tokenizationSupport.promise)) : languages.TokenizationRegistry.isResolved(nestedLanguageId) || promises.push(languages.TokenizationRegistry.getOrCreate(nestedLanguageId));
      }
      return promises.length === 0 ? {loaded:!0} : {loaded:!1, promise:Promise.all(promises).then(_ => {
      })};
    }
    getInitialState() {
      const rootState = MonarchStackElementFactory.create(null, this._lexer.start);
      return MonarchLineStateFactory.create(rootState, null);
    }
    tokenize(line, hasEOL, lineState) {
      if (line.length >= this._maxTokenizationLineLength) {
        return (0,require$_DOT__DOT__SLASH__DOT__DOT__SLASH__DOT__DOT__SLASH_common_SLASH_languages_SLASH_nullTokenize_DOT_js.nullTokenize)(this._languageId, lineState);
      }
      const tokensCollector = new MonarchClassicTokensCollector();
      line = this._tokenize(line, hasEOL, lineState, tokensCollector);
      return tokensCollector.finalize(line);
    }
    tokenizeEncoded(line, hasEOL, lineState) {
      if (line.length >= this._maxTokenizationLineLength) {
        return (0,require$_DOT__DOT__SLASH__DOT__DOT__SLASH__DOT__DOT__SLASH_common_SLASH_languages_SLASH_nullTokenize_DOT_js.nullTokenizeEncoded)(this._languageService.languageIdCodec.encodeLanguageId(this._languageId), lineState);
      }
      const tokensCollector = new MonarchModernTokensCollector(this._languageService, this._standaloneThemeService.getColorTheme().tokenTheme);
      line = this._tokenize(line, hasEOL, lineState, tokensCollector);
      return tokensCollector.finalize(line);
    }
    _tokenize(line, hasEOL, lineState, collector) {
      return lineState.embeddedLanguageData ? this._nestedTokenize(line, hasEOL, lineState, 0, collector) : this._myTokenize(line, hasEOL, lineState, 0, collector);
    }
    _findLeavingNestedLanguageOffset(line, state) {
      var rules = this._lexer.tokenizer[state.stack.state];
      if (!rules && (rules = monarchCommon.findRules(this._lexer, state.stack.state), !rules)) {
        throw monarchCommon.createError(this._lexer, "tokenizer state is not defined: " + state.stack.state);
      }
      let popOffset = -1, hasEmbeddedPopRule = !1;
      for (const rule of rules) {
        if (monarchCommon.isIAction(rule.action) && rule.action.nextEmbedded === "@pop") {
          hasEmbeddedPopRule = !0;
          var regex = rule.regex;
          rules = rule.regex.source;
          rules.substr(0, 4) === "^(?:" && rules.substr(rules.length - 1, 1) === ")" && (regex = (regex.ignoreCase ? "i" : "") + (regex.unicode ? "u" : ""), regex = new RegExp(rules.substr(4, rules.length - 5), regex));
          rules = line.search(regex);
          rules === -1 || rules !== 0 && rule.matchOnlyAtLineStart || !(popOffset === -1 || rules < popOffset) || (popOffset = rules);
        }
      }
      if (!hasEmbeddedPopRule) {
        throw monarchCommon.createError(this._lexer, 'no rule containing nextEmbedded: "@pop" in tokenizer embedded state: ' + state.stack.state);
      }
      return popOffset;
    }
    _nestedTokenize(line, hasEOL, lineState, offsetDelta, tokensCollector) {
      const popOffset = this._findLeavingNestedLanguageOffset(line, lineState);
      if (popOffset === -1) {
        return hasEOL = tokensCollector.nestedLanguageTokenize(line, hasEOL, lineState.embeddedLanguageData, offsetDelta), MonarchLineStateFactory.create(lineState.stack, new EmbeddedLanguageData(lineState.embeddedLanguageData.languageId, hasEOL));
      }
      const nestedLanguageLine = line.substring(0, popOffset);
      nestedLanguageLine.length > 0 && tokensCollector.nestedLanguageTokenize(nestedLanguageLine, !1, lineState.embeddedLanguageData, offsetDelta);
      line = line.substring(popOffset);
      return this._myTokenize(line, hasEOL, lineState, offsetDelta + popOffset, tokensCollector);
    }
    _safeRuleName(rule) {
      return rule ? rule.name : "(unknown)";
    }
    _myTokenize(lineWithoutLF, hasEOL, lineState, offsetDelta, tokensCollector) {
      tokensCollector.enterLanguage(this._languageId);
      const lineWithoutLFLength = lineWithoutLF.length, line = hasEOL && this._lexer.includeLF ? lineWithoutLF + "\n" : lineWithoutLF, lineLength = line.length;
      let embeddedLanguageData = lineState.embeddedLanguageData, stack = lineState.stack, pos = 0;
      var groupMatching = null;
      for (lineState = !0; lineState || pos < lineLength;) {
        var pos0 = pos;
        const stackLen0 = stack.depth, groupLen0 = groupMatching ? groupMatching.groups.length : 0, state = stack.state;
        var matches = null;
        let matched = null;
        var action = null, rule = null;
        let enteringEmbeddedLanguage = null;
        if (groupMatching) {
          matches = groupMatching.matches, rule = groupMatching.groups.shift(), matched = rule.matched, action = rule.action, rule = groupMatching.rule, groupMatching.groups.length === 0 && (groupMatching = null);
        } else {
          if (!lineState && pos >= lineLength) {
            break;
          }
          lineState = !1;
          var rules = this._lexer.tokenizer[state];
          if (!rules && (rules = monarchCommon.findRules(this._lexer, state), !rules)) {
            throw monarchCommon.createError(this._lexer, "tokenizer state is not defined: " + state);
          }
          var restOfLine = line.substr(pos);
          for (const rule of rules) {
            if (pos === 0 || !rule.matchOnlyAtLineStart) {
              if (matches = restOfLine.match(rule.regex)) {
                matched = matches[0];
                action = rule.action;
                break;
              }
            }
          }
        }
        matches || (matches = [""], matched = "");
        action || (pos < lineLength && (matches = [line.charAt(pos)], matched = matches[0]), action = this._lexer.defaultToken);
        if (matched === null) {
          break;
        }
        for (pos += matched.length; monarchCommon.isFuzzyAction(action) && monarchCommon.isIAction(action) && action.test;) {
          action = action.test(matched, matches, state, pos === lineLength);
        }
        rules = null;
        if (typeof action === "string" || Array.isArray(action)) {
          rules = action;
        } else if (action.group) {
          rules = action.group;
        } else if (action.token !== null && action.token !== void 0) {
          rules = action.tokenSubst ? monarchCommon.substituteMatches(this._lexer, action.token, matched, matches, state) : action.token;
          if (action.nextEmbedded) {
            if (action.nextEmbedded === "@pop") {
              if (!embeddedLanguageData) {
                throw monarchCommon.createError(this._lexer, "cannot pop embedded language if not inside one");
              }
              embeddedLanguageData = null;
            } else {
              if (embeddedLanguageData) {
                throw monarchCommon.createError(this._lexer, "cannot enter embedded language from within an embedded language");
              }
              enteringEmbeddedLanguage = monarchCommon.substituteMatches(this._lexer, action.nextEmbedded, matched, matches, state);
            }
          }
          action.goBack && (pos = Math.max(0, pos - action.goBack));
          if (action.switchTo && typeof action.switchTo === "string") {
            if (restOfLine = monarchCommon.substituteMatches(this._lexer, action.switchTo, matched, matches, state), restOfLine[0] === "@" && (restOfLine = restOfLine.substr(1)), monarchCommon.findRules(this._lexer, restOfLine)) {
              stack = stack.switchTo(restOfLine);
            } else {
              throw monarchCommon.createError(this._lexer, "trying to switch to a state '" + restOfLine + "' that is undefined in rule: " + this._safeRuleName(rule));
            }
          } else {
            if (action.transform && typeof action.transform === "function") {
              throw monarchCommon.createError(this._lexer, "action.transform not supported");
            }
            if (action.next) {
              if (action.next === "@push") {
                if (stack.depth >= this._lexer.maxStack) {
                  throw monarchCommon.createError(this._lexer, "maximum tokenizer stack size reached: [" + stack.state + "," + stack.parent.state + ",...]");
                }
                stack = stack.push(state);
              } else if (action.next === "@pop") {
                if (stack.depth <= 1) {
                  throw monarchCommon.createError(this._lexer, "trying to pop an empty stack in rule: " + this._safeRuleName(rule));
                }
                stack = stack.pop();
              } else if (action.next === "@popall") {
                stack = stack.popall();
              } else {
                if (restOfLine = monarchCommon.substituteMatches(this._lexer, action.next, matched, matches, state), restOfLine[0] === "@" && (restOfLine = restOfLine.substr(1)), monarchCommon.findRules(this._lexer, restOfLine)) {
                  stack = stack.push(restOfLine);
                } else {
                  throw monarchCommon.createError(this._lexer, "trying to set a next state '" + restOfLine + "' that is undefined in rule: " + this._safeRuleName(rule));
                }
              }
            }
          }
          action.log && typeof action.log === "string" && monarchCommon.log(this._lexer, this._lexer.languageId + ": " + monarchCommon.substituteMatches(this._lexer, action.log, matched, matches, state));
        }
        if (rules === null) {
          throw monarchCommon.createError(this._lexer, "lexer rule has no well-defined action in rule: " + this._safeRuleName(rule));
        }
        action = enteringEmbeddedLanguage => {
          enteringEmbeddedLanguage = this._languageService.getLanguageIdByLanguageName(enteringEmbeddedLanguage) || this._languageService.getLanguageIdByMimeType(enteringEmbeddedLanguage) || enteringEmbeddedLanguage;
          enteringEmbeddedLanguage = this._getNestedEmbeddedLanguageData(enteringEmbeddedLanguage);
          if (pos < lineLength) {
            const restOfLine = lineWithoutLF.substr(pos);
            return this._nestedTokenize(restOfLine, hasEOL, MonarchLineStateFactory.create(stack, enteringEmbeddedLanguage), offsetDelta + pos, tokensCollector);
          }
          return MonarchLineStateFactory.create(stack, enteringEmbeddedLanguage);
        };
        if (Array.isArray(rules)) {
          if (groupMatching && groupMatching.groups.length > 0) {
            throw monarchCommon.createError(this._lexer, "groups cannot be nested: " + this._safeRuleName(rule));
          }
          if (matches.length !== rules.length + 1) {
            throw monarchCommon.createError(this._lexer, "matched number of groups does not match the number of actions in rule: " + this._safeRuleName(rule));
          }
          groupMatching = 0;
          for (pos0 = 1; pos0 < matches.length; pos0++) {
            groupMatching += matches[pos0].length;
          }
          if (groupMatching !== matched.length) {
            throw monarchCommon.createError(this._lexer, "with groups, all characters should be matched in consecutive groups in rule: " + this._safeRuleName(rule));
          }
          groupMatching = {rule, matches, groups:[]};
          for (pos0 = 0; pos0 < rules.length; pos0++) {
            groupMatching.groups[pos0] = {action:rules[pos0], matched:matches[pos0 + 1]};
          }
          pos -= matched.length;
        } else {
          if (rules === "@rematch" && (pos -= matched.length, matched = "", matches = null, rules = "", enteringEmbeddedLanguage !== null)) {
            return action(enteringEmbeddedLanguage);
          }
          if (matched.length === 0) {
            if (lineLength === 0 || stackLen0 !== stack.depth || state !== stack.state || (groupMatching ? groupMatching.groups.length : 0) !== groupLen0) {
              continue;
            } else {
              throw monarchCommon.createError(this._lexer, "no progress in tokenizer in rule: " + this._safeRuleName(rule));
            }
          }
          matches = null;
          if (monarchCommon.isString(rules) && rules.indexOf("@brackets") === 0) {
            matches = rules.substr(9);
            rule = findBracket(this._lexer, matched);
            if (!rule) {
              throw monarchCommon.createError(this._lexer, "@brackets token returned but no bracket defined as: " + matched);
            }
            matches = monarchCommon.sanitize(rule.token + matches);
          } else {
            matches = monarchCommon.sanitize(rules === "" ? "" : rules + this._lexer.tokenPostfix);
          }
          pos0 < lineWithoutLFLength && tokensCollector.emit(pos0 + offsetDelta, matches);
          if (enteringEmbeddedLanguage !== null) {
            return action(enteringEmbeddedLanguage);
          }
        }
      }
      return MonarchLineStateFactory.create(stack, embeddedLanguageData);
    }
    _getNestedEmbeddedLanguageData(languageId) {
      if (!this._languageService.isRegisteredLanguageId(languageId)) {
        return new EmbeddedLanguageData(languageId, require$_DOT__DOT__SLASH__DOT__DOT__SLASH__DOT__DOT__SLASH_common_SLASH_languages_SLASH_nullTokenize_DOT_js.NullState);
      }
      languageId !== this._languageId && (this._languageService.requestBasicLanguageFeatures(languageId), languages.TokenizationRegistry.getOrCreate(languageId), this._embeddedLanguages[languageId] = !0);
      const tokenizationSupport = languages.TokenizationRegistry.get(languageId);
      return tokenizationSupport ? new EmbeddedLanguageData(languageId, tokenizationSupport.getInitialState()) : new EmbeddedLanguageData(languageId, require$_DOT__DOT__SLASH__DOT__DOT__SLASH__DOT__DOT__SLASH_common_SLASH_languages_SLASH_nullTokenize_DOT_js.NullState);
    }
  };
  MonarchTokenizer = MonarchTokenizer_1 = exports([__param(4, require.IConfigurationService)], MonarchTokenizer);
};

//# sourceMappingURL=module$node_modules$monaco_editor$esm$vs$editor$standalone$common$monarch$monarchLexer.js.map
